{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Intro","text":""},{"location":"#description","title":"Description","text":"<p>This webpage contains the documentation necessary to run multiple pipelines developped for the NCI-RBL.</p>"},{"location":"DTEG/descript/","title":"Description","text":""},{"location":"DTEG/descript/#dteg","title":"DTEG","text":"<p>This pipeline integrates RNA-seq and Ribo-seq to calculate translation efficiency as the number of ribosomes per gene, normalized to transcript abundance. Genes with significant changes in translation efficiency between conditions are considered to undergo translational regulation and are labelled Differential Translation Efficiency Genes (DTEGs).</p> <p>See the original publication and GitHub repository for more information.</p> <p>To run this pipeline, you will need to have NextFlow and Singularity installed (already available on Biowulf and FRCE).</p> <p>For more questions about this wrapper of the DTEG pipeline, you may contact Colin Wu or Wilfried Guiblet.</p>"},{"location":"DTEG/init/","title":"Initialize","text":""},{"location":"DTEG/init/#prepare-directories","title":"Prepare directories","text":"<p>Create a working directory and subdirectories:</p> <pre><code>mkdir DTEG\ncd DTEG\nmkdir FASTQ\nmkdir HTSeq\n</code></pre> <p>Create a subdirectory for each sample. Example:</p> <pre><code>mkdir FASTQ/HEK_WT1\nmkdir FASTQ/HEK_WT2\nmkdir FASTQ/HEK_ThumD_KO1\nmkdir FASTQ/HEK_ThumD_KO2\nmkdir FASTQ/HEK293ThumpD1KO1RNA\nmkdir FASTQ/HEK293ThumpD1KO2RNA\nmkdir FASTQ/HEK293WT1RNA\nmkdir FASTQ/HEK293WT2RNA\n</code></pre>"},{"location":"DTEG/init/#index","title":"Index","text":"<p>You can link the pre-made index folder for hg19 in the working directory:</p> <pre><code>ln -s /mnt/rnabl-work/Guiblet/CCBRRBL8/NextFlow ./\n</code></pre> <p>You can create a new index as follow: TBA</p>"},{"location":"DTEG/init/#scripts","title":"Scripts","text":"<p>Download the following files in the working directory:</p> <ul> <li>DTEG_RBL.nf</li> <li>DTEG_RBL.sh</li> <li>nextflow.config</li> </ul> <p>Open the nextflow.config file and change /mnt/rnabl-work/Guiblet/CCBRRBL8/NextFlow/ to your working directory (full path)</p>"},{"location":"DTEG/init/#sample-info","title":"Sample Info","text":"<p>Create the sample_info.txt as the following example:</p> <pre><code>SampleID        Condition       SeqType Batch\nHEK_WT1 1       RIBO    1\nHEK_WT2 1       RIBO    2\nHEK_ThumD_KO1   2       RIBO    1\nHEK_ThumD_KO2   2       RIBO    2\nHEK293WT1RNA    1       RNA     1\nHEK293WT2RNA    1       RNA     2\nHEK293ThumpD1KO1RNA     2       RNA     1\nHEK293ThumpD1KO2RNA     2       RNA     2 \n</code></pre>"},{"location":"DTEG/run/","title":"Run","text":""},{"location":"DTEG/run/#run-pipeline","title":"Run pipeline:","text":"<p>Simply submit the pipeline as a slurm job:</p> <pre><code>sbatch DTEG_RBL.sh\n</code></pre> <p>If you do not have slurm and/or are running the pipeline on a local computer (not recommended), you may run the different parts of the workflow as follow:</p> <pre><code>nextflow run -c nextflow.config test.nf --SampleInfo sample_info.txt --Process AlignRNA\nnextflow run -c nextflow.config test.nf --SampleInfo sample_info.txt --Process RunRiboSeq\nnextflow run -c nextflow.config test.nf --SampleInfo sample_info.txt --Process RunHTseq\nnextflow run -c nextflow.config test.nf --SampleInfo sample_info.txt --Process MergeCounts\nnextflow run -c nextflow.config test.nf --SampleInfo sample_info.txt --Process DTEG\n</code></pre> <p>Running this pipeline will download the Docker container in a folder named \"work\". To remove the container, delete the folder.</p> <pre><code>rm -r work\n</code></pre>"},{"location":"ISOMIR/descript/","title":"Description","text":""},{"location":"ISOMIR/descript/#isomir","title":"ISOMIR","text":"<p>Steps of the pipeline:</p> <ul> <li>Adapter removal</li> <li>Small RNA profiling</li> <li>QuagmiR analysis</li> </ul> <p>For more questions about this wrapper of the ISOMIR pipeline, you may contact Shuo Guo or Wilfried Guiblet.</p>"},{"location":"ISOMIR/init/","title":"Initialize","text":""},{"location":"ISOMIR/init/#prepare-directories","title":"Prepare directories","text":"<p>Create a working directory and subdirectories:</p> <p><pre><code>mkdir ISOMIR\ncd ISOMIR\nmkdir fastq_files\n</code></pre> Move all your experimental FastQ files in the fastq_files directory.</p>"},{"location":"ISOMIR/init/#index","title":"Index","text":"<p>You will need an Index directory for mapping to rRNA, tRNA, snoRNA, miRNA, transcriptome, and mycoplasma. You can download this Index for hg38. Extract the downloaded directory :</p> <pre><code>tar zxvf index.tar.gz\n</code></pre>"},{"location":"ISOMIR/init/#scripts","title":"Scripts","text":"<p>Download the following files in the working directory:</p> <ul> <li>isomiR.nf</li> <li>isomiR.sh</li> <li>nextflow.config</li> <li>motif-consensus.fa</li> </ul>"},{"location":"ISOMIR/run/","title":"Run","text":""},{"location":"ISOMIR/run/#run-pipeline","title":"Run pipeline:","text":"<p>Simply submit the pipeline as a slurm job:</p> <pre><code>sbatch isomiR.sh &lt;ExperimentName&gt; \"&lt;Options&gt;\"\n</code></pre> <p>Example run:</p> <pre><code>sbatch isomiR.sh Name \"--trimmer Qiagen --MinLen 18 --consensus motif-consensus.fa --index hg38\"\n</code></pre> <p>List of options.</p> <ul> <li> <p>--trimmer : Trimmer used. Default is Qiagen.</p> <ul> <li>Qiagen</li> <li>Illumina</li> <li>NEB</li> <li>GuLab</li> <li>None</li> </ul> </li> <li> <p>--MinLen: Minimum length for trimming. Requires an integer. Default is 18.</p> </li> <li> <p>--consensus : alternative consensus file.</p> </li> <li> <p>--index : Index for profiling. Currently available:</p> <ul> <li>hg38</li> <li>mm39</li> </ul> </li> <li> <p>--sRNAprofiling : Yes or No. No skips this step.</p> </li> <li> <p>--QuagmiR : Yes or No. No skips this step.</p> </li> </ul>"},{"location":"MOP2/descript/","title":"Description","text":""},{"location":"MOP2/descript/#mop2","title":"MOP2","text":"<p>This document describes how to use the Master Of Pores V2 (MOP2) pipeline on the FRCE server. MOP2 estimates the length of mRNA poly-A tail from Nanopore reads using Tailfindr and Nanopolish.</p> <p>See the original publication and GitHub repository for more information.</p>"},{"location":"MOP2/init/","title":"Initialize","text":""},{"location":"MOP2/init/#prepare-directories","title":"Prepare directories","text":"<p>Create a working directory and subdirectories:</p> <pre><code>mkdir MOP2\ncd MOP2\nmkdir MOP2_work\nmkdir MOP2_output\n</code></pre>"},{"location":"MOP2/init/#scripts-and-dependencies","title":"Scripts and dependencies","text":"<p>Copy the following files and folders in your working directory:</p> <pre><code>cp /scratch/cluster_scratch/guibletwm/MOP2_repo/ ./\n</code></pre> <p>Download the following files in the working directory:</p> <ul> <li>PolyATail.sh</li> </ul>"},{"location":"MOP2/init/#paths","title":"Paths","text":"<p>Modify the following paths in PolyATail.sh:</p> <ul> <li>basedir</li> <li>nextflow</li> <li>procdir</li> </ul>"},{"location":"MOP2/run/","title":"Run","text":""},{"location":"MOP2/run/#run-pipeine","title":"Run pipeine:","text":"<p>Use the command:</p> <p>bash PolyATail.sh /path_to_fast5_files/</p> <p>The script will ask for a short project name. Intermediary files will be stored in the MOP2_work folder. PolyA-tail lengths will be copied in the MOP2_output. ~</p>"},{"location":"RiboFootPrint/descript/","title":"Description","text":""},{"location":"RiboFootPrint/descript/#ribofootprint","title":"RiboFootPrint","text":"<p>Steps of the pipeline:</p> <ul> <li>Trimm Ribo-seq reads.</li> <li>Filter out reads mapping to non-coding RNA and remap (STAR) to transcriptome.</li> <li>Aggregates relative postions (range: 0-1) of read starts, split in 5'UTR, CDS, and 3'UTR.</li> </ul> <p>For more questions about this pipeline, you may contact Colin Wu or Wilfried Guiblet.</p>"},{"location":"RiboFootPrint/init/","title":"Initialize","text":""},{"location":"RiboFootPrint/init/#scripts","title":"Scripts","text":"<p>Download all scripts from RiboFootPrint GitHub repository</p>"},{"location":"RiboFootPrint/init/#index","title":"Index","text":"<p>You can link the pre-made index folder for hg19 in the working directory:</p> <pre><code>ln -s /mnt/rnabl-work/Guiblet/CCRRBL12/index ./\n</code></pre>"},{"location":"RiboFootPrint/init/#set-parameters","title":"Set Parameters","text":"<p>Update the file: RiboFootPrint.parameters.yaml </p>"},{"location":"RiboFootPrint/run/","title":"Run","text":""},{"location":"RiboFootPrint/run/#run-pipeline","title":"Run pipeline:","text":"<p>Simply submit the pipeline as a slurm job:</p> <pre><code>sbatch RiboFootPrint.sh\n</code></pre> <p>If your previous run was not completed and you wish to resume, resubmit the slurm job as:</p> <pre><code>sbatch RiboFootPrint.sh -resume\n</code></pre> <p>Running this pipeline will download a Docker container in a folder named \"work\". To remove the container, delete the folder.</p> <pre><code>rm -r work\n</code></pre>"},{"location":"eCLIP/eCLIP_workflow/","title":"eCLIP Workflow","text":"<p>The eCLIP Workflow implemented here was designed to run on a High-performance Cluster such as Biowulf or FRCE. The heart of the workflow analysis uses the eCLIP workflow from Yeo Lab's.</p> <p>Detailed information on required software can be found using the following links:</p> <ol> <li>Slurm workload Manager</li> <li>Environmental Modules</li> <li>SingularityCE</li> <li>git</li> <li>eCLIP from Yeo Lab.</li> <li>MultiQC from Seqera.</li> </ol> <p>The first four items are typically provided by a High-performance Cluster such as Biowulf or FRCE.</p>"},{"location":"eCLIP/eCLIP_workflow/#setting-up-eclip-workflow","title":"Setting Up eCLIP Workflow","text":""},{"location":"eCLIP/eCLIP_workflow/#create-an-environment-to-run-eclip-workflow-on-frce","title":"Create an Environment to Run eCLIP Workflow on FRCE","text":"<pre><code>module load mamba\n\nmamba create -n cwl_env conda-forge::tabulate conda-forge::cwltool matplotlib\n\nmamba activate cwl_env\npip install multiqc\n\nmultiqc --version\n</code></pre>"},{"location":"eCLIP/eCLIP_workflow/#download-yeo-labs-github-repository","title":"Download Yeo Lab's GitHub Repository","text":"<pre><code>SCRIPT_DIR=/home/$USER/eCLIP_WF\nmkdir $SCRIPT_DIR\n\ncd $SCRIPT_DIR\ngit clone git@github.com:YeoLab/eCLIP.git\n\nECLIP_DIR=$SCRIPT_DIR/eCLIP\nls -l $ECLIP_DIR\n</code></pre>"},{"location":"eCLIP/eCLIP_workflow/#download-custom-scripts-to-run-the-pipeline-on-biowulf-frce","title":"Download custom scripts to run the pipeline on biowulf / FRCE","text":"<ol> <li>env.yml</li> <li>post_process_eCLIP.py</li> <li>run.sh</li> <li>summarize_merge_peaks_wf.py</li> </ol>"},{"location":"eCLIP/eCLIP_workflow/#setting-up-required-files-and-directories","title":"Setting Up Required Files and Directories","text":"<p>Directory locations should be based on the preferences of the user. As an example, we provide the following set up below as set up on FRCE. It is recommend that you separate the results or runs directory from the data directory. A full description of required files is located with links below:</p> <ul> <li>Prerequisite files</li> <li>Description of the manifest File</li> </ul> <pre><code>DATA_DIR=/home/$USER/Data\nRUN_DIR=/scratch/cluster_scratch/$USER/eCLIP_run\n\nmkdir $DATA_DIR\nmkdir $RUN_DIR\n</code></pre> <p>Create a manifest directory and manifest file as required by eCLIP.</p> <pre><code>MANIFEST_DIR=$DATA_DIR/manifests\nmkdir $MANIFEST_DIR\n\n# For single-end reads copy, modify and rename file\ncp $ECLIP_DIR/example/single_end_clip.yaml $MANIFEST_DIR/\n</code></pre>"},{"location":"eCLIP/eCLIP_workflow/#modify-the-run-script","title":"Modify the Run Script","text":"<p>Modify the run.sh script file.</p>"},{"location":"eCLIP/eCLIP_workflow/#running-workflow","title":"Running Workflow","text":"<p>The workflow has two major parts:</p> <ol> <li>Run YeoLab's eCLIP.</li> <li>Followed by YeoLab's merge_peaks</li> </ol> <pre><code>sbatch run.sh\n</code></pre>"},{"location":"eCLIP/eCLIP_workflow/#results","title":"Results","text":"<p>A full description of results files are located with eCLIP Outputs and merge_peaks Outputs.</p> <p>We provide two summary html files are generated:</p> <ol> <li>eCLIP_ReadMeSummary.html summary results file as a starting point for exploration of your results of eCLIP, and</li> <li>eCLIP_MergePeaks_ReadMeSummary.html for merge_peaks.</li> </ol>"},{"location":"iCLIP/descript/","title":"Description","text":""},{"location":"iCLIP/descript/#iclip","title":"iCLIP","text":"<p>This pipelines process and analyzes iCLIP data from raw fasqt files.</p> <p>Steps of the pipeline:</p> <p></p> <p>For more questions about this pipeline, you may contact Wilfried Guiblet.</p>"},{"location":"iCLIP/init/","title":"Initialize","text":""},{"location":"iCLIP/init/#scripts","title":"Scripts","text":"<p>Download nextflow.parameters.yaml in your directory. Update the parameters to fit your experiment.</p>"},{"location":"iCLIP/run/","title":"Run","text":""},{"location":"iCLIP/run/#run-pipeline","title":"Run pipeline:","text":"<p>On biowulf,</p> <p>Load the latest version of the pipeline: <pre><code>export PATH=$PATH:/data/RBL_NCI/iCLIP/latest/\n</code></pre></p> <p>Run the pipeline with genomic coordinates: <pre><code>sbatch iCLIP_latest.sh \"your_directory\"\n</code></pre></p> <p>After running with genomic coordinates, you can also run for transcriptomic coordinates: <pre><code>sbatch iCLIP_Transcriptome_latest.sh \"your_directory\"\n</code></pre></p> <p>You can add the option <code>-resume</code> to resume a failed/interrupted run.</p>"}]}